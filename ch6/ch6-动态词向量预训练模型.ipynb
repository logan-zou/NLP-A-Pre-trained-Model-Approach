{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELMo词向量模型"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zouyuheng/.conda/envs/zyh_pytorch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建文本预定义标记\n",
    "BOS_TOKEN = \"<bos>\"\n",
    "EOS_TOKEN = \"<eos>\"\n",
    "PAD_TOKEN = \"<pad>\"\n",
    "BOW_TOKEN = \"<bow>\"\n",
    "EOW_TOKEN = \"<eow>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建词表函数\n",
    "def load_corpus(path, max_tok_len=None, max_seq_len=None):\n",
    "    '''\n",
    "    path:本地文本数据路径\n",
    "    max_tok_len:词长度上限\n",
    "    max_seq_len:序列长度上限\n",
    "    '''\n",
    "    text = []\n",
    "    charset = {BOS_TOKEN, EOS_TOKEN, PAD_TOKEN, BOW_TOKEN, EOW_TOKEN}\n",
    "    # 字符集，首先加入预定义标记\n",
    "    with open(path, \"r\") as f:\n",
    "        # 读取文本文件\n",
    "        for line in tqdm(f):\n",
    "            # 文件中每一行是一段字符序列\n",
    "            tokens = line.rstrip().split(\" \")\n",
    "            # rstrip函数用于删除字符串末尾的空白\n",
    "            if max_seq_len is not None and len(tokens) + 2 > max_seq_len:\n",
    "                # 之后要加入BOS_TOKEN和EOS_TOKEN两个标记，所以要留出两个位置\n",
    "                tokens = line[:max_seq_len-2]\n",
    "                # 截断过长的序列\n",
    "            sent = [BOS_TOKEN]\n",
    "            # 当前序列\n",
    "            for token in tokens:\n",
    "                if max_tok_len is not None and len(token) + 2 > max_tok_len:\n",
    "                    # 同理，要加入BOW_TOKEN和EOW_TOKEN\n",
    "                    # 注意，因为ELMo模型使用了字符级输入，所以除构建词级语料外，还要构建字符级语料\n",
    "                    token = token[:max_tok_len-2]\n",
    "                sent.append(token)\n",
    "                for ch in token:\n",
    "                    charset.add(ch)\n",
    "                    # 将字符加入字符集\n",
    "            sent.append(EOS_TOKEN)\n",
    "            text.append(sent)\n",
    "    # 此处处理之后，text中的一个元素为一个序列即一个sent，sent中的一个元素为一个标注即一个token\n",
    "    # print(text[:10])\n",
    "    \n",
    "    vocab_w = Vocab.build(text, min_freq=2, reserved_tokens=[PAD_TOKEN, BOS_TOKEN, EOS_TOKEN])\n",
    "    # 词级词表，需要先统计token，因此使用build方法\n",
    "    vocab_c = Vocab(tokens=list(charset))\n",
    "    # 字符级词表，charset是已经统计好的字符，因此无需统计，直接构建\n",
    "\n",
    "    corpus_w = [vocab_w.convert_tokens_to_ids(sent) for sent in text]\n",
    "    # 构建词级语料\n",
    "    corpus_c = []\n",
    "    bow = vocab_c[BOW_TOKEN]\n",
    "    eow = vocab_c[EOW_TOKEN]\n",
    "    for i, sent in enumerate(text):\n",
    "        sent_c = []\n",
    "        for token in sent:\n",
    "            if token == BOS_TOKEN or token == EOS_TOKEN:\n",
    "                token_c = [bow, vocab_c[token], eow]\n",
    "            # 如果token不是一个词\n",
    "            else:\n",
    "                token_c = [bow] + vocab_c.convert_tokens_to_ids(token) + [eow]\n",
    "            sent_c.append(token_c)\n",
    "        # 这一块代码整体是将文本转化为索引，对于正常token，直接调用转化函数即可，对于标记类token，则直接查找对应索引\n",
    "        # 因为convert函数内部会将传入参数拆开依次映射，因此vocab_c传入token，但其实映射的是token内部的字符\n",
    "        corpus_c.append(sent_c)\n",
    "\n",
    "    return corpus_w, corpus_c, vocab_w, vocab_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 词表构建方法同之前一样\n",
    "# 构建Vocab类\n",
    "from collections import defaultdict\n",
    "\n",
    "class Vocab:\n",
    "\n",
    "    def __init__(self, tokens = None) -> None:\n",
    "        self.idx_to_token = list()\n",
    "        self.token_to_idx = dict()\n",
    "\n",
    "        if tokens is not None:\n",
    "            if \"<unk>\" not in tokens:\n",
    "                tokens += [\"<unk>\"]\n",
    "            for token in tokens:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "            self.unk = self.token_to_idx[\"<unk>\"] \n",
    "\n",
    "    @classmethod\n",
    "    def build(cls, text, min_freq = 1, reserved_tokens = None):\n",
    "        # cls 为类本身，相当于Vocab()\n",
    "        token_freqs = defaultdict(int) # 统计token的频率\n",
    "        for sentence in text:\n",
    "            for token in sentence:\n",
    "                token_freqs[token] += 1\n",
    "        uniq_tokens = [\"<unk>\"] + (reserved_tokens if reserved_tokens else [])\n",
    "        uniq_tokens += [token for token, freq in token_freqs.items()  \n",
    "                       if freq >= min_freq and token != \"<unk>\"]\n",
    "        return cls(uniq_tokens)\n",
    "        \n",
    "    def __len__(self):\n",
    "        # 返回词表的大小\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, token):\n",
    "        # 查找输入token对应的索引值，如果不存在返回<unk>对应的索引0\n",
    "        return self.token_to_idx.get(token, self.unk)\n",
    "\n",
    "    def convert_tokens_to_ids(self, tokens):\n",
    "        return [self[token] for token in tokens]\n",
    "\n",
    "    def convert_ids_to_tokens(self, indices):\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "145321it [00:05, 27047.84it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus_w, corpus_c, vocab_w, vocab_c = load_corpus(\"/home/zouyuheng/data/English/travel_comment.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建用于双向语言模型的数据集\n",
    "class BiLMDataset(Dataset):\n",
    "\n",
    "    def __init__(self, corpus_w, corpus_c, vocab_w, vocab_c) -> None:\n",
    "        super(BiLMDataset, self).__init__()\n",
    "        self.pad_w = vocab_w[PAD_TOKEN]\n",
    "        self.pad_c = vocab_c[PAD_TOKEN]\n",
    "\n",
    "        self.data = []\n",
    "        for sent_w, sent_c in zip(corpus_w, corpus_c):\n",
    "            self.data.append((sent_w, sent_c))\n",
    "        # print(self.data[0][1])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = BiLMDataset(corpus_w, corpus_c, vocab_c, vocab_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples, pad_w, pad_c):\n",
    "    \n",
    "    seq_lens = torch.LongTensor([len(ex[0]) for ex in examples])\n",
    "    # ex为每段文本，ex[0]为以词划分的序列\n",
    "    # 样本中序列的长度，使用LongTensor函数进行数据类型的转换\n",
    "    inputs_w = [torch.tensor(ex[0]) for ex in examples]\n",
    "    # 词级别输入\n",
    "    inputs_w = pad_sequence(inputs_w, batch_first=True, padding_value=pad_w)\n",
    "    # 对每个序列补齐到相同长度\n",
    "\n",
    "    batch_size, max_seq_len = inputs_w.shape\n",
    "    # 词级别的输入矩阵为批次大小*序列长度，因为之前做了补齐，所以所有长度皆为最长序列长度\n",
    "    max_tok_len = max([max([len(tok) for tok in ex[1]]) for ex in examples])\n",
    "    # ex[1]为以字符划分的序列，tok为以字符表示的每个词\n",
    "    # 找出最大词大小\n",
    "\n",
    "    inputs_c = torch.LongTensor(batch_size, max_seq_len, max_tok_len).fill_(pad_c)\n",
    "    # 字符级别的输入矩阵为批次大小*序列长度*最大词大小,使用pad初始化\n",
    "    # 字符比词更深一层\n",
    "    for i, (sent_w, sent_c) in enumerate(examples):\n",
    "        for j, tok in enumerate(sent_c):\n",
    "            inputs_c[i][j][:len(tok)] = torch.LongTensor(tok)\n",
    "            # 此处使用索引起到了补齐的作用\n",
    "\n",
    "    targets_fw = torch.LongTensor(inputs_w.shape).fill_(pad_w)\n",
    "    # 前向语言模型的目标输出序列\n",
    "    targets_bw = torch.LongTensor(inputs_w.shape).fill_(pad_w)\n",
    "    # 后向语言模型的目标输出序列\n",
    "    for i, (sent_w, sent_c) in enumerate(examples):\n",
    "        targets_fw[i][:len(sent_w)-1] = torch.LongTensor(sent_w[1:])\n",
    "        # 前向语言模型的目标输出序列为输入序列左移一位\n",
    "        targets_bw[i][1:len(sent_w)] = torch.LongTensor(sent_w[:len(sent_w)-1])\n",
    "    # 对于前向语言模型，输入为<bos>w1w2w3...<eos>，输出为w1w2w3...<eos><pad>\n",
    "    # 计算时输入<bos>输出w1，输入w1和历史状态（<bos>）输出w2，以此类推\n",
    "    # 对于后向语言模型，输入为<bos>w1w2w3...<eos>，输出为<pad><bos>w1w2...wn\n",
    "\n",
    "    return inputs_w, inputs_c, seq_lens, targets_fw, targets_bw"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Highway(nn.Module):\n",
    "    # 基于字符的输入表示层，即Highway网络\n",
    "    def __init__(self, input_dim, num_layers, activation = F.relu) -> None:\n",
    "        super(Highway, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.layers = nn.ModuleList(\n",
    "            [nn.Linear(input_dim, input_dim * 2) for _ in range(num_layers)]\n",
    "        )\n",
    "        # 使用ModuleList构建多个线性层，每层的输入为input_dim，输出为两倍input_dim，其中一半输入下一层，一半用于计算门控\n",
    "        self.activation = activation\n",
    "        for layer in self.layers:\n",
    "            layer.bias[input_dim:].data.fill_(1)\n",
    "        # 后半部分是计算门控向量的参数,即公式中的W^g和b^g\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        curr_inputs = inputs\n",
    "        # 整体输入\n",
    "        for layer in self.layers:\n",
    "            projected_inputs = layer(curr_inputs)\n",
    "            # 经过线性层计算\n",
    "            hidden = self.activation(projected_inputs[:, 0:self.input_dim])\n",
    "            # 前半部分通过激活作为当前隐藏层输出\n",
    "            gate = torch.sigmoid(projected_inputs[:, self.input_dim:])\n",
    "            # 后半部分计算门控向量\n",
    "            curr_inputs = gate * curr_inputs + (1 - gate) * hidden\n",
    "        return curr_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvTokenEmbedder(nn.Module):\n",
    "    # 基于字符卷积的词表示层\n",
    "    def __init__(self, vocab_c, char_embedding_dim, char_conv_filters, num_highways, output_dim, pad = \"<pad>\") -> None:\n",
    "        '''\n",
    "        Args:\n",
    "           vocab_c: 字符级词表\n",
    "           char_embedding_dim: 字符向量维度\n",
    "           char_conv_filters: 卷积核大小，双层列表\n",
    "           num_highways: highway网络层数 \n",
    "           output_dim: 输出维度\n",
    "        '''\n",
    "        super(ConvTokenEmbedder, self).__init__()\n",
    "        self.vocab_c = vocab_c\n",
    "        self.char_embeddings = nn.Embedding(len(vocab_c), char_embedding_dim, padding_idx=vocab_c[pad])\n",
    "        # 词向量层，注意，此处的len(vocab_c)并不是输入维度，而是词表大小\n",
    "        # self.char_embeddings.data.uniform(-0.25, 0.25)\n",
    "        # uniform随机取值，对参数进行初始化\n",
    "\n",
    "        self.convolutions = nn.ModuleList()\n",
    "        # 卷积层\n",
    "        for kernel_size, out_channels in char_conv_filters:\n",
    "            conv = nn.Conv1d(in_channels=char_embedding_dim, out_channels=out_channels, kernel_size=kernel_size, bias=True)\n",
    "            self.convolutions.append(conv)\n",
    "        # 创建多个一维卷积层\n",
    "\n",
    "        self.num_filters = sum(f[1] for f in char_conv_filters)\n",
    "        # 输入highway网络时是将不同卷积核的输出拼接在了一起，所以highway网络的输入维度是所有卷积层的输出维度之和\n",
    "        self.num_highways = num_highways\n",
    "        self.highways = Highway(self.num_filters, self.num_highways, activation = F.relu)\n",
    "        self.projection = nn.Linear(self.num_filters, output_dim, bias = True)\n",
    "        '''线性层'''\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch_size, seq_len, token_len = inputs.shape\n",
    "        # 批次大小，序列长度，标记长度\n",
    "        # print(\"inputs.shape = \", inputs.shape)\n",
    "        inputs = inputs.view(batch_size * seq_len, -1)\n",
    "        # 将输入展开为二维，以token为单位，所以需要将批次和序列长度整合\n",
    "        # print(\"after view, inputs.shape = \", inputs.shape)\n",
    "        # print(\"len(vocab_c) = \", len(self.vocab_c))\n",
    "        char_embeds = self.char_embeddings(inputs)\n",
    "        # print(\"char_embeds.shape = \", char_embeds.shape)\n",
    "        char_embeds = char_embeds.transpose(1, 2)\n",
    "        # 做转置原因：卷积的输入定义不同，为批次*输入通道数*长度，表示层输出为批次*长度*输入通道数\n",
    "        # 注意，由于将token拆成了字符，此处的批次其实为批次*token数\n",
    "\n",
    "        conv_hiddens = []\n",
    "        for i in range(len(self.convolutions)):\n",
    "            # 逐个卷积操作\n",
    "            conv_hidden = self.convolutions[i](char_embeds)\n",
    "            conv_hidden, _ = torch.max(conv_hidden, dim = -1)\n",
    "            # 最大池化\n",
    "            conv_hidden = F.relu(conv_hidden)\n",
    "            conv_hiddens.append(conv_hidden)\n",
    "\n",
    "        token_embeds = torch.cat(conv_hiddens, dim=-1)\n",
    "        # 将不同卷积层的输出拼接\n",
    "        token_embeds = self.highways(token_embeds)\n",
    "        token_embeds = self.projection(token_embeds)\n",
    "        token_embeds = token_embeds.view(batch_size, seq_len, -1)\n",
    "        # 将输出的形状还原\n",
    "        return token_embeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELMoLSTMEncoder(nn.Module):\n",
    "    # 双向LSTM编码器\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers) -> None:\n",
    "        \n",
    "        super(ELMoLSTMEncoder, self).__init__()\n",
    "        self.projection_dim = input_dim\n",
    "        # 用于投影层，保证各层具有相同的维度\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.forward_layers = nn.ModuleList()\n",
    "        # 前向LSTM\n",
    "        self.forward_projections = nn.ModuleList()\n",
    "        # 投影层：hidden_dim -> projection_dim\n",
    "        self.backward_layers= nn.ModuleList()\n",
    "        # 后向LSTM\n",
    "        self.backward_projections = nn.ModuleList()\n",
    "        # 后向投影层同前向\n",
    "\n",
    "        lstm_input_dim = input_dim\n",
    "        for _ in range(num_layers):\n",
    "            forward_layer = nn.LSTM(lstm_input_dim, hidden_dim, num_layers=1, batch_first=True)\n",
    "            forward_projection = nn.Linear(hidden_dim, self.projection_dim, bias=True)\n",
    "            # 单层前向LSTM以及投影层\n",
    "            backward_layer = nn.LSTM(lstm_input_dim, hidden_dim, num_layers=1, batch_first=True)\n",
    "            backward_projection = nn.Linear(hidden_dim, self.projection_dim, bias=True)\n",
    "            # 单层后向LSTM以及投影层\n",
    "            lstm_input_dim = self.projection_dim\n",
    "            self.forward_layers.append(forward_layer)\n",
    "            self.forward_projections.append(forward_projection)\n",
    "            self.backward_layers.append(backward_layer)\n",
    "            self.backward_projections.append(backward_projection)\n",
    "\n",
    "    def forward(self, inputs, lengths):\n",
    "        batch_size, seq_len, input_dim = inputs.shape\n",
    "        \n",
    "        rev_idx = torch.arange(seq_len).unsqueeze(0).repeat(batch_size, 1)\n",
    "        # print(\"最初的rev_idx\")\n",
    "        # print(rev_idx)\n",
    "        for i in range(lengths.shape[0]):\n",
    "            rev_idx[i, :lengths[i]] = torch.arange(lengths[i]-1, -1, -1)\n",
    "            # print(\"经过第{}次处理之后的rev_idx\")\n",
    "            # print(rev_idx)\n",
    "        rev_idx = rev_idx.unsqueeze(2).expand_as(inputs)\n",
    "        # print(\"处理之后的rev_idx\")\n",
    "        # print(rev_idx)\n",
    "        rev_idx = rev_idx.to(inputs.device)\n",
    "        rev_inputs = inputs.gather(1, rev_idx)\n",
    "        '''此处不是特别清晰'''\n",
    "\n",
    "        forward_inputs, backward_inputs = inputs, rev_inputs\n",
    "        # 前向和后向的输入\n",
    "        stacked_forward_states, stacked_backward_states = [], []\n",
    "        # 前向和后向的隐含层状态\n",
    "\n",
    "        for layer_index in range(self.num_layers):\n",
    "            \n",
    "            packed_forward_inputs = pack_padded_sequence(forward_inputs, lengths, batch_first=True, enforce_sorted=False)\n",
    "            packed_backward_inputs = pack_padded_sequence(backward_inputs, lengths, batch_first=True, enforce_sorted=False)\n",
    "            # 对前后向输入进行打包对齐\n",
    "            \n",
    "            forward_layer = self.forward_layers[layer_index]\n",
    "            packed_forward, _ = forward_layer(packed_forward_inputs)\n",
    "            forward = pad_packed_sequence(packed_forward, batch_first=True)[0]\n",
    "            # 对输出解包\n",
    "            forward = self.forward_projections[layer_index](forward)\n",
    "            # 规整宽度\n",
    "            stacked_forward_states.append(forward)\n",
    "            # 计算前向LSTM\n",
    "\n",
    "            backward_layer = self.backward_layers[layer_index]\n",
    "            packed_backward, _ = backward_layer(packed_backward_inputs)\n",
    "            backward = pad_packed_sequence(packed_backward, batch_first=True)[0]\n",
    "            backward = self.backward_projections[layer_index](backward)\n",
    "            stacked_backward_states.append(backward.gather(1, rev_idx))\n",
    "            # 将输出还原顺序\n",
    "            # 计算后向LSTM\n",
    "\n",
    "        return stacked_forward_states, stacked_backward_states \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数\n",
    "config = {\n",
    "    'max_tok_len' : 50,\n",
    "    'train_file': \"/home/zouyuheng/data/English/travel_comment.txt\",\n",
    "    'model_path' : './elmo_bilm',\n",
    "    'char_embedding_dim':50,\n",
    "    'char_conv_filters':[[1, 32], [2, 32], [3, 64], [4, 128], [5, 256], [6, 512], [7, 1024]],\n",
    "    'num_highways':2,\n",
    "    'projection_dim':512,\n",
    "    'hidden_dim':4096,\n",
    "    \"num_layers\":2,\n",
    "    'batch_size':4,\n",
    "    \"dropout\":0.1, \n",
    "    'learning_rate':0.0004,\n",
    "    \"clip_grad\":5,\n",
    "    'num_epoch':10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 双向语言模型\n",
    "class BiLM(nn.Module):\n",
    "    def __init__(self, configs, vocab_w, vocab_c) -> None:\n",
    "        super(BiLM, self).__init__()\n",
    "        self.dropout_prob = configs[\"dropout\"]\n",
    "        self.num_classes = len(vocab_w)\n",
    "        # 输出层的维度为词表大小，即对词表中的每一个词有一个预测概率\n",
    "\n",
    "        self.token_embedder = ConvTokenEmbedder(vocab_c, configs['char_embedding_dim'], configs['char_conv_filters'], configs['num_highways'], configs['projection_dim'])\n",
    "        # 词表示编码器\n",
    "        self.encoder = ELMoLSTMEncoder(configs['projection_dim'], configs['hidden_dim'], configs['num_layers'])\n",
    "        # ELMo编码器\n",
    "        self.classifier = nn.Linear(configs['projection_dim'], self.num_classes)\n",
    "        # 分类器\n",
    "\n",
    "    def forward(self, inputs, lengths):\n",
    "        token_embeds = self.token_embedder(inputs)\n",
    "        token_embeds = F.dropout(token_embeds, self.dropout_prob)\n",
    "        # 采样\n",
    "        forward, backward = self.encoder(token_embeds, lengths.to('cpu'))\n",
    "        return self.classifier(forward[-1]), self.classifier(backward[-1])\n",
    "        # 使用最后的隐藏状态作为分类器的输入\n",
    "        # 此处注意，ELMo模型的原思想应该是对各个隐藏状态做线性组合，此处做了简化\n",
    "\n",
    "    def save_pretrained(self, path):\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        torch.save(self.token_embedder.state_dict(), os.path.join(\"token_embedder.pth\"))\n",
    "        # 保存词表示编码器的参数\n",
    "        torch.save(self.encoder.state_dict(), os.path.join(\"encoder.pth\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "145321it [00:07, 19774.60it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus_w, corpus_c, vocab_w, vocab_c = load_corpus(config['train_file'])\n",
    "train_data = BiLMDataset(corpus_w, corpus_c, vocab_w, vocab_c)\n",
    "train_loader = DataLoader(train_data, config['batch_size'], collate_fn = lambda x : collate_fn(x, vocab_w[PAD_TOKEN], vocab_c[PAD_TOKEN]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index = vocab_w[PAD_TOKEN], reduction='sum')\n",
    "# 使用交叉熵损失函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLM(config, vocab_w, vocab_c)\n",
    "# 构建模型\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(filter(lambda x: x.requires_grad, model.parameters()), lr = config['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 0:   0%|          | 23/36331 [00:11<5:07:33,  1.97it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [31], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m# 计算后向模型损失\u001b[39;00m\n\u001b[1;32m     16\u001b[0m loss \u001b[39m=\u001b[39m (loss_fw \u001b[39m+\u001b[39m loss_bw) \u001b[39m/\u001b[39m \u001b[39m2.0\u001b[39m\n\u001b[0;32m---> 17\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     18\u001b[0m \u001b[39m# 反向传播\u001b[39;00m\n\u001b[1;32m     19\u001b[0m nn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), config[\u001b[39m'\u001b[39m\u001b[39mclip_grad\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/.conda/envs/zyh_pytorch/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/.conda/envs/zyh_pytorch/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(config['num_epoch']):\n",
    "    total_loss = 0\n",
    "    total_tags = 0\n",
    "    # 有效预测位置的数量\n",
    "    for batch in tqdm(train_loader, desc = f\"Training Epoch {epoch}\"):\n",
    "        batch = [x.to(device) for x in batch]\n",
    "        inputs_w, inputs_c, seq_lens, targets_fw, targets_bw = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs_fw, outputs_bw = model(inputs_c, seq_lens)\n",
    "        # 模型计算输出\n",
    "        loss_fw = criterion(outputs_fw.view(-1, outputs_fw.shape[-1]), targets_fw.view(-1))\n",
    "        # 计算前向模型损失\n",
    "        loss_bw = criterion(outputs_bw.view(-1, outputs_bw.shape[-1]), targets_bw.view(-1))\n",
    "        # 计算后向模型损失\n",
    "        loss = (loss_fw + loss_bw) / 2.0\n",
    "        loss.backward()\n",
    "        # 反向传播\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), config['clip_grad'])\n",
    "        # 梯度裁剪，解决梯度爆炸问题\n",
    "        optimizer.step()\n",
    "\n",
    "    total_loss += loss_fw.item()\n",
    "    total_tags += seq_lens.sum().item()\n",
    "    train_ppl = np.exp(total_loss / total_tags)\n",
    "    # 以前向模型的困惑度作为性能指标\n",
    "    print(f\"Train PPL: {train_ppl:.2f}\")\n",
    "\n",
    "model.save_pretrained(config['model_path'])\n",
    "# 保存模型参数\n",
    "json.dump(config, open(os.path.join(config['model_path'], 'config.json'), \"w\"))\n",
    "# 保存超参数"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zyh_pytorch",
   "language": "python",
   "name": "zyh_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
